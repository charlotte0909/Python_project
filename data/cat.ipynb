{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data_training(file_name):\n",
    "\n",
    "    with open(file_name, 'rb') as f:\n",
    "        data = pkl.load(f)\n",
    "    \n",
    "    training_data = []\n",
    "\n",
    "    training_cats = data['train']['cat'] / np.max(data['train']['cat'])    \n",
    "    training_no_cats = data['train']['no_cat']/ np.max(data['train']['no_cat'])\n",
    "\n",
    "    \n",
    "    for i in range(len(training_cats)):\n",
    "        t = list(training_cats[i].flatten())\n",
    "        training_data.append((t,1))\n",
    "\n",
    "    for i in range(len(training_no_cats)):\n",
    "        m = list(training_no_cats[i].flatten())\n",
    "        training_data.append((m, 0))\n",
    "    \n",
    "    random.shuffle(training_data)\n",
    "    \n",
    "    return training_data\n",
    "\n",
    "training = load_data_training('cat_data.pkl')\n",
    "len(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_testing(file_name):\n",
    "\n",
    "    with open(file_name, 'rb') as f:\n",
    "        data = pkl.load(f)\n",
    "    \n",
    "    testing_data = []\n",
    "\n",
    "    testing_cats = data['test']['cat'] / np.max(data['test']['cat'])    \n",
    "    testing_no_cats = data['test']['no_cat']/ np.max(data['test']['no_cat'])\n",
    "   \n",
    "    for i in range(len(testing_cats)):\n",
    "        m = list(testing_cats[i].flatten())\n",
    "        testing_data.append((m,1))\n",
    "\n",
    "    for i in range(len(testing_no_cats)):\n",
    "        m = list(testing_no_cats[i].flatten())\n",
    "        testing_data.append((m, 0))\n",
    "    \n",
    "    random.shuffle(testing_data)\n",
    "    \n",
    "    return testing_data\n",
    "\n",
    "testing = load_data_testing('cat_data.pkl')\n",
    "len(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def save_pkl(file_name, data):\n",
    "            with open(file_name, 'wb') as f:\n",
    "                pkl.dump(data, f)\n",
    "\n",
    "class Neuron:\n",
    "\n",
    "    def __init__(self, dimension=1, weights=None, bias=None, activation=(lambda x: x), predict=(lambda x: x)):\n",
    "        self._dim = dimension\n",
    "        self.w = weights or np.array([random.random()*(-1)**random.randint(0, 1) for _ in range(self._dim)])\n",
    "        self.w = np.array([float(w) for w in self.w])\n",
    "        self.b = bias if bias is not None else random.random()*(-1)**random.randint(0, 1)\n",
    "        self.b = float(self.b)\n",
    "        self._a = activation\n",
    "        self.predict = predict.__get__(self)\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Simple cell neuron\\n\\\n",
    "        \\tInput dimension: %d\\n\\\n",
    "        \\tBias: %f\\n\\\n",
    "        \\tWeights: %s\\n\\\n",
    "        \\tActivation: %s\" % (self._dim, self.b, self.w, self._a.__name__)\n",
    "\n",
    "    def __call__(self, x):\n",
    "    \n",
    "        yhat = self._a(np.dot(self.w, np.array(x)) + self.b)\n",
    "        return yhat\n",
    "    \n",
    "class Trainer:\n",
    "\n",
    "    def __init__(self, dataset, model, loss):\n",
    "    \n",
    "        self.dataset = dataset\n",
    "        self.model = model\n",
    "        self.loss = loss\n",
    "\n",
    "    def validate(self, data):\n",
    "\n",
    "        results = [self.loss(self.model.predict(x), y) for x, y in data]\n",
    "        return float(sum(result for result in results))/float(len(results))\n",
    "    \n",
    "    def accuracy(self, data):\n",
    "        return 100*float(sum([1 for x, y in data if self.model.predict(x) == y]))/float(len(data))\n",
    "\n",
    "    def train(self, lr, ne):\n",
    "\n",
    "        print(\"training model on data...\")\n",
    "        accuracy = self.accuracy(self.dataset)\n",
    "        print(\"initial accuracy: %.3f\" % (accuracy))\n",
    "        for epoch in range(ne):\n",
    "            for d in self.dataset:\n",
    "                x, y = d\n",
    "                x = np.array(x)\n",
    "                yhat = self.model(x)\n",
    "                error = y - yhat\n",
    "                self.model.w += lr*(y-yhat)*x\n",
    "                self.model.b += lr*(y-yhat)\n",
    "            accuracy = self.accuracy(self.dataset)\n",
    "            print('>epoch=%d, learning_rate=%.3f, accuracy=%.3f' % (epoch+1, lr, accuracy))\n",
    "        print(\"training complete\")\n",
    "        print(\"final accuracy: %.3f\" % (self.accuracy(self.dataset)))\n",
    "\n",
    "# activation functions\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def perceptron(z):\n",
    "    return -1 if z<=0 else 1\n",
    "\n",
    "# loss functions\n",
    "\n",
    "def lrloss(yhat, y):\n",
    "    return -1.0*(y*np.log(yhat)+(1-y)*np.log(1-yhat))\n",
    "\n",
    "def ploss(yhat, y):\n",
    "    return max(0, -yhat*y)\n",
    "\n",
    "# prediction functions\n",
    "\n",
    "def ppredict(self, x):\n",
    "    return self(x)\n",
    "\n",
    "def lrpredict(self, x):\n",
    "    return 1 if self(x)>0.5 else 0\n",
    "    \n",
    "# extra\n",
    "\n",
    "def softmax(z):\n",
    "    return np.exp(z) / np.sum(np.exp(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model on data...\n",
      "initial accuracy: 52.632\n",
      ">epoch=1, learning_rate=0.010, accuracy=59.809\n",
      ">epoch=2, learning_rate=0.010, accuracy=66.986\n",
      ">epoch=3, learning_rate=0.010, accuracy=70.335\n",
      ">epoch=4, learning_rate=0.010, accuracy=61.722\n",
      ">epoch=5, learning_rate=0.010, accuracy=58.373\n",
      ">epoch=6, learning_rate=0.010, accuracy=71.292\n",
      ">epoch=7, learning_rate=0.010, accuracy=61.722\n",
      ">epoch=8, learning_rate=0.010, accuracy=63.158\n",
      ">epoch=9, learning_rate=0.010, accuracy=85.167\n",
      ">epoch=10, learning_rate=0.010, accuracy=67.464\n",
      ">epoch=11, learning_rate=0.010, accuracy=69.378\n",
      ">epoch=12, learning_rate=0.010, accuracy=89.474\n",
      ">epoch=13, learning_rate=0.010, accuracy=80.383\n",
      ">epoch=14, learning_rate=0.010, accuracy=67.464\n",
      ">epoch=15, learning_rate=0.010, accuracy=92.344\n",
      ">epoch=16, learning_rate=0.010, accuracy=69.378\n",
      ">epoch=17, learning_rate=0.010, accuracy=92.344\n",
      ">epoch=18, learning_rate=0.010, accuracy=92.344\n",
      ">epoch=19, learning_rate=0.010, accuracy=86.124\n",
      ">epoch=20, learning_rate=0.010, accuracy=92.823\n",
      ">epoch=21, learning_rate=0.010, accuracy=91.388\n",
      ">epoch=22, learning_rate=0.010, accuracy=93.780\n",
      ">epoch=23, learning_rate=0.010, accuracy=84.211\n",
      ">epoch=24, learning_rate=0.010, accuracy=93.780\n",
      ">epoch=25, learning_rate=0.010, accuracy=93.780\n",
      ">epoch=26, learning_rate=0.010, accuracy=94.737\n",
      ">epoch=27, learning_rate=0.010, accuracy=95.215\n",
      ">epoch=28, learning_rate=0.010, accuracy=89.952\n",
      ">epoch=29, learning_rate=0.010, accuracy=94.258\n",
      ">epoch=30, learning_rate=0.010, accuracy=96.651\n",
      ">epoch=31, learning_rate=0.010, accuracy=97.129\n",
      ">epoch=32, learning_rate=0.010, accuracy=68.421\n",
      ">epoch=33, learning_rate=0.010, accuracy=94.258\n",
      ">epoch=34, learning_rate=0.010, accuracy=93.780\n",
      ">epoch=35, learning_rate=0.010, accuracy=94.737\n",
      ">epoch=36, learning_rate=0.010, accuracy=95.694\n",
      ">epoch=37, learning_rate=0.010, accuracy=91.866\n",
      ">epoch=38, learning_rate=0.010, accuracy=96.651\n",
      ">epoch=39, learning_rate=0.010, accuracy=96.651\n",
      ">epoch=40, learning_rate=0.010, accuracy=94.737\n",
      ">epoch=41, learning_rate=0.010, accuracy=97.129\n",
      ">epoch=42, learning_rate=0.010, accuracy=80.861\n",
      ">epoch=43, learning_rate=0.010, accuracy=97.129\n",
      ">epoch=44, learning_rate=0.010, accuracy=96.651\n",
      ">epoch=45, learning_rate=0.010, accuracy=96.651\n",
      ">epoch=46, learning_rate=0.010, accuracy=96.172\n",
      ">epoch=47, learning_rate=0.010, accuracy=98.565\n",
      ">epoch=48, learning_rate=0.010, accuracy=95.694\n",
      ">epoch=49, learning_rate=0.010, accuracy=98.086\n",
      ">epoch=50, learning_rate=0.010, accuracy=99.043\n",
      ">epoch=51, learning_rate=0.010, accuracy=98.565\n",
      ">epoch=52, learning_rate=0.010, accuracy=96.651\n",
      ">epoch=53, learning_rate=0.010, accuracy=97.608\n",
      ">epoch=54, learning_rate=0.010, accuracy=99.522\n",
      ">epoch=55, learning_rate=0.010, accuracy=99.043\n",
      ">epoch=56, learning_rate=0.010, accuracy=99.522\n",
      ">epoch=57, learning_rate=0.010, accuracy=99.522\n",
      ">epoch=58, learning_rate=0.010, accuracy=99.522\n",
      ">epoch=59, learning_rate=0.010, accuracy=99.522\n",
      ">epoch=60, learning_rate=0.010, accuracy=99.522\n",
      ">epoch=61, learning_rate=0.010, accuracy=99.522\n",
      ">epoch=62, learning_rate=0.010, accuracy=99.522\n",
      ">epoch=63, learning_rate=0.010, accuracy=99.522\n",
      ">epoch=64, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=65, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=66, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=67, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=68, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=69, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=70, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=71, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=72, learning_rate=0.010, accuracy=99.522\n",
      ">epoch=73, learning_rate=0.010, accuracy=99.522\n",
      ">epoch=74, learning_rate=0.010, accuracy=99.522\n",
      ">epoch=75, learning_rate=0.010, accuracy=99.522\n",
      ">epoch=76, learning_rate=0.010, accuracy=99.522\n",
      ">epoch=77, learning_rate=0.010, accuracy=99.043\n",
      ">epoch=78, learning_rate=0.010, accuracy=98.565\n",
      ">epoch=79, learning_rate=0.010, accuracy=98.565\n",
      ">epoch=80, learning_rate=0.010, accuracy=98.565\n",
      ">epoch=81, learning_rate=0.010, accuracy=98.565\n",
      ">epoch=82, learning_rate=0.010, accuracy=98.565\n",
      ">epoch=83, learning_rate=0.010, accuracy=98.565\n",
      ">epoch=84, learning_rate=0.010, accuracy=99.043\n",
      ">epoch=85, learning_rate=0.010, accuracy=99.043\n",
      ">epoch=86, learning_rate=0.010, accuracy=99.043\n",
      ">epoch=87, learning_rate=0.010, accuracy=99.043\n",
      ">epoch=88, learning_rate=0.010, accuracy=99.043\n",
      ">epoch=89, learning_rate=0.010, accuracy=99.522\n",
      ">epoch=90, learning_rate=0.010, accuracy=99.522\n",
      ">epoch=91, learning_rate=0.010, accuracy=99.522\n",
      ">epoch=92, learning_rate=0.010, accuracy=99.522\n",
      ">epoch=93, learning_rate=0.010, accuracy=99.522\n",
      ">epoch=94, learning_rate=0.010, accuracy=99.522\n",
      ">epoch=95, learning_rate=0.010, accuracy=99.522\n",
      ">epoch=96, learning_rate=0.010, accuracy=99.522\n",
      ">epoch=97, learning_rate=0.010, accuracy=99.522\n",
      ">epoch=98, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=99, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=100, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=101, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=102, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=103, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=104, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=105, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=106, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=107, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=108, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=109, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=110, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=111, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=112, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=113, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=114, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=115, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=116, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=117, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=118, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=119, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=120, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=121, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=122, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=123, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=124, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=125, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=126, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=127, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=128, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=129, learning_rate=0.010, accuracy=100.000\n",
      ">epoch=130, learning_rate=0.010, accuracy=100.000\n",
      "training complete\n",
      "final accuracy: 100.000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cat_bw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-81c9a864ac31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcats_bw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneuron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mneuron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msave_pkl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cats_bw.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_bw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cats_bw.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cat_bw' is not defined"
     ]
    }
   ],
   "source": [
    "neuron = Neuron(dimension = 64*64*3, activation = sigmoid, predict = lrpredict)\n",
    "trainer = Trainer(training, neuron, lrloss)\n",
    "updates = trainer.train(0.01, 130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12289"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats_bw = list([neuron.b, *neuron.w])\n",
    "save_pkl('cats_bw.pkl', cats_bw)\n",
    "\n",
    "with open('cats_bw.pkl', 'rb') as f:\n",
    "    loadedneuron = pkl.load(f)\n",
    "\n",
    "len(loadedneuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tester:\n",
    "\n",
    "    def __init__(self, dataset, model, loss):\n",
    "    \n",
    "        self.dataset = dataset\n",
    "        self.model = model\n",
    "        self.loss = loss\n",
    "\n",
    "    def validate(self, data):\n",
    "\n",
    "        results = [self.loss(self.model.predict(x), y) for x, y in data]\n",
    "        return float(sum(result for result in results))/float(len(results))\n",
    "    \n",
    "    def accuracy(self, data):\n",
    "        return 100*float(sum([1 for x, y in data if self.model.predict(x) == y]))/float(len(data))\n",
    "\n",
    "    def test(self):\n",
    "        print(\"testing model on data...\")\n",
    "        accuracy = self.accuracy(self.dataset)\n",
    "        print(\"initial accuracy: %.3f\" % (accuracy))\n",
    "        for d in self.dataset:\n",
    "            x, y = d\n",
    "            x = np.array(x)\n",
    "            yhat = self.model(x)\n",
    "            error = y - yhat\n",
    "            accuracy = self.accuracy(self.dataset)\n",
    "        print('accuracy=%.3f' % (accuracy))\n",
    "        print(\"testing complete\")\n",
    "        print(\"final accuracy: %.3f\" % (self.accuracy(self.dataset)))\n",
    "        \n",
    "# activation function\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "# loss function\n",
    "\n",
    "def lrloss(yhat, y):\n",
    "    return -1.0*(y*np.log(yhat)+(1-y)*np.log(1-yhat))\n",
    "\n",
    "# prediction function\n",
    "\n",
    "def lrpredict(self, x):\n",
    "    return 1 if self(x)>0.5 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing model on data...\n",
      "initial accuracy: 60.000\n",
      "accuracy=60.000\n",
      "testing complete\n",
      "final accuracy: 60.000\n"
     ]
    }
   ],
   "source": [
    "tester = Tester(testing, neuron, lrloss)\n",
    "tester.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
